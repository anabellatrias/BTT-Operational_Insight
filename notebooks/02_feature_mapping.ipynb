{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Mapping Notebook\n",
    "\n",
    "This notebook maps the features available in the 5k labeled dataset to the 2k operational dataset. The objective is to identify which fields exist in both datasets, which require transformation, and which cannot be used. This mapping ensures that the downstream feature engineering produces features compatible with both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# LOAD DATASETS\n",
    "clean_data_path = Path(\"../data/clean\")\n",
    "data_path = Path(\"../data/raw\")\n",
    "\n",
    "clean_2k = pd.read_csv(clean_data_path / \"2k_clean.csv\")\n",
    "clean_5k = pd.read_csv(clean_data_path / \"5kp_clean.csv\")\n",
    "df_activity_ref = pd.read_csv(data_path / \"Activity_Reference.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Mapping Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FEATURE MAPPING TABLE:\n",
      "                5k_column     2k_column       status                              transformation\n",
      "                  case_id       case_id DIRECT MATCH                                        None\n",
      "        event_num_in_case      event_nr DIRECT MATCH                               Rename column\n",
      "            activity_name      activity DIRECT MATCH                        Different activities\n",
      "      is_bottleneck_event       MISSING     NO MATCH         Cannot derive directly from 2k data\n",
      "         duration_minutes  duration_sec  CONVERTIBLE                           duration_sec / 60\n",
      "        wait_time_minutes wait_time_sec  CONVERTIBLE                          wait_time_sec / 60\n",
      "expected_duration_minutes    CAN DERIVE   CALCULABLE        Lookup from activity_reference table\n",
      "     variance_to_expected CAN CALCULATE   CALCULABLE    (duration_minutes - expected) / expected\n",
      "    queue_length_at_start       MISSING     NO MATCH  Count concurrent active cases at timestamp\n",
      "   system_load_index_0to1       MISSING     NO MATCH Rolling avg of wait_time, normalized to 0-1\n",
      "     handoff_count_so_far CAN CALCULATE   CALCULABLE             Count resource changes per case\n",
      "                  weekday       weekday DIRECT MATCH                                        None\n",
      "              hour_of_day          hour DIRECT MATCH                               Rename column\n",
      "      start_timestamp_utc     timestamp      PARTIAL   2k only has one timestamp (not start/end)\n",
      "                 priority      priority DIRECT MATCH    May need to map values (Low/Medium/High)\n",
      "             sla_breached    sla_breach DIRECT MATCH                  Check value encoding (0/1)\n",
      "                     NONE      cost_usd   PLUS BONUS                 Use for business validation\n",
      "                     NONE   rework_flag   PLUS BONUS                 Use for business validation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "feature_mapping = [\n",
    "    {\n",
    "        '5k_column': 'case_id',\n",
    "        '2k_column': 'case_id',\n",
    "        'status': 'DIRECT MATCH',\n",
    "        'transformation': 'None'\n",
    "    },\n",
    "    {\n",
    "        '5k_column': 'event_num_in_case',\n",
    "        '2k_column': 'event_nr',\n",
    "        'status': 'DIRECT MATCH',\n",
    "        'transformation': 'Rename column'\n",
    "    },\n",
    "    {\n",
    "        '5k_column': 'activity_name',\n",
    "        '2k_column': 'activity',\n",
    "        'status': 'DIRECT MATCH',\n",
    "        'transformation': 'Different activities'\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        '5k_column': 'is_bottleneck_event',\n",
    "        '2k_column': 'MISSING',\n",
    "        'status': 'NO MATCH',\n",
    "        'transformation': 'Cannot derive directly from 2k data'\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        '5k_column': 'duration_minutes',\n",
    "        '2k_column': 'duration_sec',\n",
    "        'status': 'CONVERTIBLE',\n",
    "        'transformation': 'duration_sec / 60'\n",
    "    },\n",
    "    {\n",
    "        '5k_column': 'wait_time_minutes',\n",
    "        '2k_column': 'wait_time_sec',\n",
    "        'status': 'CONVERTIBLE',\n",
    "        'transformation': 'wait_time_sec / 60'\n",
    "    },\n",
    "    {\n",
    "        '5k_column': 'expected_duration_minutes',\n",
    "        '2k_column': 'CAN DERIVE',\n",
    "        'status': 'CALCULABLE',\n",
    "        'transformation': 'Lookup from activity_reference table'\n",
    "    },\n",
    "    {\n",
    "        '5k_column': 'variance_to_expected',\n",
    "        '2k_column': 'CAN CALCULATE',\n",
    "        'status': 'CALCULABLE',\n",
    "        'transformation': '(duration_minutes - expected) / expected'\n",
    "    },\n",
    "\n",
    "    {\n",
    "        '5k_column': 'queue_length_at_start',\n",
    "        '2k_column': 'MISSING',\n",
    "        'status': 'NO MATCH',\n",
    "        'transformation': 'Count concurrent active cases at timestamp'\n",
    "    },\n",
    "    {\n",
    "        '5k_column': 'system_load_index_0to1',\n",
    "        '2k_column': 'MISSING',\n",
    "        'status': 'NO MATCH',\n",
    "        'transformation': 'Rolling avg of wait_time, normalized to 0-1'\n",
    "    },\n",
    "    \n",
    "    {\n",
    "        '5k_column': 'handoff_count_so_far',\n",
    "        '2k_column': 'CAN CALCULATE',\n",
    "        'status': 'CALCULABLE',\n",
    "        'transformation': 'Count resource changes per case'\n",
    "    },\n",
    "    {\n",
    "        '5k_column': 'weekday',\n",
    "        '2k_column': 'weekday',\n",
    "        'status': 'DIRECT MATCH',\n",
    "        'transformation': 'None'\n",
    "    },\n",
    "    {\n",
    "        '5k_column': 'hour_of_day',\n",
    "        '2k_column': 'hour',\n",
    "        'status': 'DIRECT MATCH',\n",
    "        'transformation': 'Rename column'\n",
    "    },\n",
    "    {\n",
    "        '5k_column': 'start_timestamp_utc',\n",
    "        '2k_column': 'timestamp',\n",
    "        'status': 'PARTIAL',\n",
    "        'transformation': '2k only has one timestamp (not start/end)'\n",
    "    },\n",
    "    \n",
    "    # Business context\n",
    "    {\n",
    "        '5k_column': 'priority',\n",
    "        '2k_column': 'priority',\n",
    "        'status': 'DIRECT MATCH',\n",
    "        'transformation': 'May need to map values (Low/Medium/High)'\n",
    "    },\n",
    "    {\n",
    "        '5k_column': 'sla_breached',\n",
    "        '2k_column': 'sla_breach',\n",
    "        'status': 'DIRECT MATCH',\n",
    "        'transformation': 'Check value encoding (0/1)'\n",
    "    },\n",
    "    \n",
    "    # Additional 2k features (not in 5k)\n",
    "    {\n",
    "        '5k_column': 'NONE',\n",
    "        '2k_column': 'cost_usd',\n",
    "        'status': 'PLUS BONUS',\n",
    "        'transformation': 'Use for business validation'\n",
    "    },\n",
    "    {\n",
    "        '5k_column': 'NONE',\n",
    "        '2k_column': 'rework_flag',\n",
    "        'status': 'PLUS BONUS',\n",
    "        'transformation': 'Use for business validation'\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "mapping_df = pd.DataFrame(feature_mapping)\n",
    "\n",
    "print(\"\\nFEATURE MAPPING TABLE:\")\n",
    "print(mapping_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activity Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVITY NAME MATCHING\n",
      "\n",
      "Activities in 5k dataset:\n",
      "  - Approve Budget (optional)\n",
      "  - Assign Resource\n",
      "  - Close Ticket\n",
      "  - Execute Task\n",
      "  - Quality Check\n",
      "  - Receive Request\n",
      "  - Validate Request\n",
      "  - Vendor Review (optional)\n",
      "\n",
      "Total unique activities in 5k: 8\n",
      "\n",
      "Activities in 2k dataset:\n",
      "  - Classify Request\n",
      "  - Close Ticket\n",
      "  - Enrich Data\n",
      "  - Fulfill Request\n",
      "  - Manual Approval\n",
      "  - Notify Customer\n",
      "  - Quality Check\n",
      "  - Receive Request\n",
      "\n",
      "Total unique activities in 2k: 8\n",
      "\n",
      "Activities in Reference Table:\n",
      "  - Approve Budget (optional)\n",
      "  - Assign Resource\n",
      "  - Close Ticket\n",
      "  - Execute Task\n",
      "  - Quality Check\n",
      "  - Receive Request\n",
      "  - Validate Request\n",
      "  - Vendor Review (optional)\n",
      "\n",
      "Total activities defined in reference: 8\n",
      "MATCHING ANALYSIS:\n",
      "\n",
      "5k activities IN reference table: 8/8\n",
      "\n",
      "2k activities IN reference table: 3/8\n",
      "  Missing from reference:\n",
      "    Classify Request\n",
      "    Enrich Data\n",
      "    Manual Approval\n",
      "    Fulfill Request\n",
      "    Notify Customer\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"ACTIVITY NAME MATCHING\")\n",
    "\n",
    "\n",
    "print(\"\\nActivities in 5k dataset:\")\n",
    "activities_5k = clean_5k['activity_name'].unique()\n",
    "for act in sorted(activities_5k):\n",
    "    print(f\"  - {act}\")\n",
    "\n",
    "print(f\"\\nTotal unique activities in 5k: {len(activities_5k)}\")\n",
    "\n",
    "print(\"\\nActivities in 2k dataset:\")\n",
    "activities_2k = clean_2k['activity'].unique()\n",
    "for act in sorted(activities_2k):\n",
    "    print(f\"  - {act}\")\n",
    "\n",
    "print(f\"\\nTotal unique activities in 2k: {len(activities_2k)}\")\n",
    "\n",
    "print(\"\\nActivities in Reference Table:\")\n",
    "activities_ref = df_activity_ref['activity_name'].unique()\n",
    "for act in sorted(activities_ref):\n",
    "    print(f\"  - {act}\")\n",
    "\n",
    "print(f\"\\nTotal activities defined in reference: {len(activities_ref)}\")\n",
    "\n",
    "# Check matches\n",
    "print(\"MATCHING ANALYSIS:\")\n",
    "\n",
    "\n",
    "# Which 5k activities are in reference?\n",
    "in_ref_5k = [act for act in activities_5k if act in activities_ref]\n",
    "not_in_ref_5k = [act for act in activities_5k if act not in activities_ref]\n",
    "\n",
    "print(f\"\\n5k activities IN reference table: {len(in_ref_5k)}/{len(activities_5k)}\")\n",
    "if not_in_ref_5k:\n",
    "    print(\"  Missing from reference:\")\n",
    "    for act in not_in_ref_5k:\n",
    "        print(f\"    {act}\")\n",
    "\n",
    "# Which 2k activities are in reference?\n",
    "in_ref_2k = [act for act in activities_2k if act in activities_ref]\n",
    "not_in_ref_2k = [act for act in activities_2k if act not in activities_ref]\n",
    "\n",
    "print(f\"\\n2k activities IN reference table: {len(in_ref_2k)}/{len(activities_2k)}\")\n",
    "if not_in_ref_2k:\n",
    "    print(\"  Missing from reference:\")\n",
    "    for act in not_in_ref_2k:\n",
    "        print(f\"    {act}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA UNDERSTANDING FINAL REPORT:\n",
    "\n",
    "DATASETS LOADED & VALIDATED:\n",
    "\n",
    "5k labeled dataset:  50 rows × 30 columns\n",
    "2k operational logs: 2,000 rows × 20 columns\n",
    "Activity reference:  8 activities defined\n",
    "\n",
    "---\n",
    "\n",
    "CLASS DISTRIBUTION (5k):\n",
    "\n",
    "Normal events:     31 (62.0%)\n",
    "Bottleneck events: 19 (38.0%)\n",
    "\n",
    "TOP BOTTLENECK PREDICTORS (from EDA):\n",
    "\n",
    "1. *** variance_to_expected:  10.02x lift (p<0.001) - CRITICAL FEATURE\n",
    "2. *   duration_minutes:      2.07x lift (p=0.049) - IMPORTANT\n",
    "3. *   wait_time_minutes:     1.65x lift (p=0.029) - IMPORTANT\n",
    "\n",
    "---\n",
    "\n",
    "KEY INSIGHT FROM FEATURE ANALYSIS:\n",
    "\n",
    "variance_to_expected (10x predictor) CAN be calculated from 2k data\n",
    "This is the dominant signal - most critical for predictions\n",
    "5k and 2k datasets have different formats (distribution mismatch)\n",
    "\n",
    "---\n",
    "\n",
    "FEATURE AVAILABILITY (5k → 2k):\n",
    "\n",
    "Direct matches:       6 features\n",
    "Convertible (units):  2 features\n",
    "Calculable (derived): 3 features\n",
    "Need proxy features: 2 features\n",
    "Total usable:         11 features\n",
    "\n",
    "---\n",
    "\n",
    "VALIDATION STRATEGY:\n",
    "\n",
    "1. Train supervised model on 5k labeled data\n",
    "2. Engineer proxy features for missing columns\n",
    "3. Validate predictions on 2k using business metrics:\n",
    "   - cost_usd correlation\n",
    "   - rework_flag lift\n",
    "   - sla_breach correlation\n",
    "4. Deploy with confidence scoring\n",
    "\n",
    "---\n",
    "\n",
    "CONFIDENCE ASSESSMENT:\n",
    "\n",
    "Strong signal exists (10x lift on top feature)\n",
    "Most important features available/calculable in 2k\n",
    "Some moderate features need proxies\n",
    "Business validation possible (cost, rework, SLA data available)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
